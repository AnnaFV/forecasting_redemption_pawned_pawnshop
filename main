# Импортируем необходимые библиотеки
import numpy as np
import pandas as pd
import gdown
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Скачиваем файл с Google Drive по ID
file_url = 'https://drive.google.com/uc?id=1m1MFG5A6uaQSRvZslzOr25ZK6XxUek_o'
output = 'pledge.csv'
gdown.download(file_url, output, quiet=False)

# Проверим, правильно ли был загружен файл
os.listdir()

# Читаем файл и создаем DataFrame
df = pd.read_csv(output, delimiter=';')
df.head()

# Изучим столбцы датасета
df.columns

# Получим форму датасета
df.shape

# И информацию о нем
df.info()

# Сделаем проверку на наличие пропущенных значений
if df.isnull().values.any():
    print("Данные содержат пропущенные значения. Обработайте их перед дальнейшими действиями.")

# Переведем столбец pledge_date в формат datatime и создадим новый столбец, в котором выделим месяц взятия залога
df['pledge_date'] = pd.to_datetime(df['pledge_date'], format="%d.%m.%Y")
df['pledge_month'] = df['pledge_date'].dt.month

# Визуализируем распределение возраста
age_counts = df['client_age'].value_counts().sort_index()
plt.figure(figsize=(12, 6))
sns.barplot(x=age_counts.index, y=age_counts.values, color='g', alpha = 0.5)
plt.title('Количество клиентов по возрасту')
plt.xlabel('Возраст')
plt.ylabel('Количество клиентов')
plt.xticks(rotation=55)
plt.grid(axis='y')
plt.show()

# Визуализируем распределение по полу
plt.figure(figsize=(8, 4))
sns.countplot(x='client_gender', data=df)
plt.title('Распределение по полу')
plt.xlabel('Пол')
plt.ylabel('Количество клиентов')
plt.xticks(ticks=[0, 1], labels=['Мужчина', 'Женщина'])
plt.show()

# Визуализируем, в какие месяцы чаще всего брали залоги
plt.figure(figsize=(8, 4))
sns.countplot(x='pledge_month', data=df)
plt.title('Распределение по месяцу')
plt.xlabel('Месяц')
plt.ylabel('Количество клиентов')
plt.show()

# Визуализируем связь количества невозвратов и количества выкупов
plt.figure(figsize=(10, 6))
sns.countplot(x='default_history_count', hue='is_redeemed', data=df, palette='pastel')
plt.title('Связь количества невозвратов и количества выкупов')
plt.xlabel('Количество невозвратов')
plt.ylabel('Количество клиентов')
plt.legend(title='Выкуп', labels=['Нет', 'Да'])
plt.grid()
plt.show()

# Построим график зависимости процентной ставки от наличия льготы и количества невозвратов ранее
plt.figure(figsize=(10, 5))
sns.scatterplot(x='default_history_count', y='interest_rate',
                hue='benefit', style='benefit', palette={0: 'red', 1: 'green'}, markers={0: 'o', 1: 's'}, data=df)
plt.title('Процентная ставка, зависящая от количеством невозвратов и наличия льготы')
plt.xlabel('Количество невозвратов')
plt.ylabel('Процентная ставка')
plt.legend(title='Наличие льготы', labels=['Да', 'Нет'])
plt.grid()
plt.show()

# Построим график, отражающий общее количество выкупов/невыкупов последнего залога
plt.figure(figsize=(6, 4))
sns.countplot(x='is_redeemed', data=df)
plt.title('Распределение по количеству выкупов/невыкупов последнего залога')
plt.xlabel('Выкупы/невыкупы')
plt.ylabel('Количество')
plt.xticks(ticks=[0, 1], labels=['Невыкупы', 'Выкупы'])
plt.show()

# Разделим данные на обучающую и тестовую выборки
X = df.drop(columns=['is_redeemed', 'pledge_date'])
y = df['is_redeemed']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1. Для сравнения обучим несколько моделей. Первая - Random Forest Classifier
# Создадим и обучим модель
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred_rand_for_cl = model.predict(X_test)

# Оценка Random Forest Classifier
print("Результаты Random Forest Classifier:")
accuracy = accuracy_score(y_test, y_pred_rand_for_cl)
print(f'Точность: {accuracy * 100:.2f}%')
print("Отчет о классификации:\n", classification_report(y_test, y_pred_rand_for_cl))

# Построим матрицу ошибок
conf_matrix = confusion_matrix(y_test, y_pred_rand_for_cl)
plt.figure(figsize=(7, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица ошибок')
plt.show()

# 2. XGBoost
# Создадим и обучим модель
xgb_model = XGBClassifier(eval_metric='logloss')
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

# Оценка XGBoost
print("Результаты XGBoost:")
accuracy = accuracy_score(y_test, y_pred_xgb)
print(f'Точность: {accuracy * 100:.2f}%')
print("Отчет о классификации:\n", classification_report(y_test, y_pred_xgb))

# Построим матрицу ошибок
conf_matrix = confusion_matrix(y_test, y_pred_xgb)
plt.figure(figsize=(7, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица ошибок')
plt.show()
